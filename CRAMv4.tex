%&pdfLaTeX
% !TEX encoding = UTF-8 Unicode
\documentclass[a4paper]{article}
\usepackage{ifxetex}
\ifxetex
\usepackage{fontspec}
\setmainfont[Mapping=tex-text]{STIXGeneral}
\else
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\fi
\usepackage{textcomp}

\usepackage{graphicx}
\usepackage{array}
\usepackage{fixltx2e}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{algpseudocode}
\usepackage{threeparttable}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\setlength{\parindent}{0cm}
\setlength{\parskip}{0.18cm}
\usepackage[hmargin=2cm,vmargin=2.5cm,bindingoffset=0.0cm]{geometry}
\usepackage[pdfborder={0 0 0}]{hyperref}
\begin{document}



\input{CRAMv3.ver}
\title{CRAM format specification (version 4.0)}
\author{samtools-devel@lists.sourceforge.net}
\date{\headdate}
\maketitle


\begin{quote}\small
The master version of this document can be found at
\url{https://github.com/samtools/hts-specs}.\\
This printing is version~\commitdesc\ from that repository,
last modified on the date shown above.
\end{quote}

\begin{center}
\textit{license: Apache 2.0}
\end{center}
\vspace*{1em}

\newlength{\maxwidth}
\newcommand{\algalign}[2] % #1 = text to left, #2 = text to right
{\makebox[\maxwidth][l]{$#1{}$}${}#2$}

\makeatletter
\newcommand*{\bdiv}{%
  \nonscript\mskip-\medmuskip\mkern5mu%
  \mathbin{\operator@font div}\penalty900\mkern5mu%
  \nonscript\mskip-\medmuskip
}
\newcommand*{\bitand}{%
  \nonscript\mskip-\medmuskip\mkern5mu%
  \mathbin{\operator@font AND}\penalty900\mkern5mu%
  \nonscript\mskip-\medmuskip
}
\newcommand*{\bitor}{%
  \nonscript\mskip-\medmuskip\mkern5mu%
  \mathbin{\operator@font OR}\penalty900\mkern5mu%
  \nonscript\mskip-\medmuskip
}
\newcommand*{\bitxor}{%
  \nonscript\mskip-\medmuskip\mkern5mu%
  \mathbin{\operator@font XOR}\penalty900\mkern5mu%
  \nonscript\mskip-\medmuskip
}
\makeatother

\subsection*{FQZComp quality codec}

The FQZComp quality codec uses an adaptive statistical model to
predict the next quality value in a given context (comprised of
previous quality values, position along this sequence, whether the
sequence is the second in a pair, and a running total of number of
times the quality has changed in this sequence).

For each quality value, the models produce probabilities for all
possible next quality values, which are passed into an arithmetic
entropy encoder to encode or decode the actual next quality value.
The models are then updated based on the actual next quality in order
to learn the statistical properties of the quality data stream.  This
step wise update process is identical for both encoding and decoding.

The algorithm is a generalisation on the original fqzcomp program,
described in \textit{Compression of FASTQ and SAM Format Sequencing
  Data} by Bonfield JK, Mahoney MV (2013). PLoS ONE 8(3):
e59190. \url{https://doi.org/10.1371/journal.pone.0059190}

\subsubsection*{Range coding}

The range coder is a byte-wise arithmetic coder that operates by
repeatedly reducing a probability range (for example 0.0 to 1.0) one
symbol (byte) at a time with the complete compressed data can be
represented by any value within the final range.

This is easiest demonstrated with a worked example, so let us imagine
we have an alphabet of 4 symbols, `t', `c', `g', and `a' with
probabilities 0.2, 0.3, 0.3 and 0.2 respectively.  We can construct a
cumulative distribution table and apply probability ranges to each of
the symbols:

\begin{tabular}{rrrr}
\hline
\textbf{Symbol} & \textbf{Probability} & \textbf{Range low} & \textbf{Range high}\\
\hline
t & 0.2 & 0.0 & 0.2 \\
c & 0.3 & 0.2 & 0.5 \\
g & 0.3 & 0.5 & 0.8 \\
a & 0.2 & 0.8 & 1.0 \\
\hline
\end{tabular}

As a \emph{conceptual example} (note: this is not how it is implemented in practice, see below) using arbitrary precision floating point mathematics this could operate as follows.

If we wish to encode a message, such as ``cat'' then we will encode
one symbol at a time (`c', `a', `t') successively reducing the
initial range of 0.0 to 1.0 by the cumulative distribution for that
symbol.  At each point the new range is adjusted to be the proportion
of the previous range covered by the cumulative symbol range.  See the
table footnotes below for the worked mathematics.

\begin{threeparttable}[t]
\begin{tabular}{rrrrr}
\hline
\textbf{Range low} & \textbf{Range high} & \textbf{Symbol} & \textbf{Symbol low} & \textbf{Symbol high}\\
\hline
0.000 & 1.000 & c & 0.2 & 0.5\\
0.200 & 0.500 & a & 0.8 & 1.0\\
0.440\tnote{\textbf{a}} & 0.500\tnote{\textbf{a}} & t & 0.0 & 0.2\\
0.440 & 0.452 & <end>\\
\hline
\end{tabular}
\begin{tablenotes}
\item{\textbf{a.}} Old range 0.2 to 0.5 plus symbol range 0.8 to 1.0 gives an updated range of 0.44 to 0.5:\\
 $0.2 + 0.8\times(0.5-0.2) = 0.44$\\
$0.2 + 1.0\times(0.5-0.2) = 0.50$
\end{tablenotes}
\end{threeparttable}

Our final range is 0.44 to 0.452 with any value in that range representing
``cat'', thus 0.45 would suffice.  A pictorial example of this process is below.

\includegraphics[height=250pt, keepaspectratio=true]{img/range_code.png}

Decoding is simply the reverse of this.  In the above picture we can see that 0.45 would read off `c', `a' and `t' by repeatedly comparing the symbol ranges to the current range and using those to identify the symbol and produce a new range.

\begin{threeparttable}[t]
\begin{tabular}{rrrr}
\hline
\textbf{Range low} & \textbf{Range high} & \textbf{Fraction into range} & \textbf{Symbol}\\
\hline
0.000 & 1.000 & 0.450 & c\\
0.200 & 0.500 & 0.833\tnote{\textbf{a}} & a\\
0.440\tnote{\textbf{b}} & 0.500 & 0.167 & t\\
\hline
\end{tabular}
\begin{tablenotes}
\item{\textbf{a.}} 0.45 into range 0.2 to 0.5: $(0.45-0.2)/(0.5-0.2) = 0.833$.
This falls within the 0.8 to 1.0 symbol range for `a'.
\item{\textbf{b.}} `a' symbol range 0.8 to 1.0 applied to range 0.2 to 0.5:  $0.2+0.8\times(0.5-0.2) = 0.44$ and $0.2+1.0\times(0.5-0.2) = 0.5$.
\end{tablenotes}
\end{threeparttable}

Note: The above example not how the actual implementation works\footnote{This implementation was designed by Eugene Shelwein.}.
For efficiency, we use integer values having a starting range of 0 to $2^{32}-1$.
We write out the top 8-bits of the range when low and high become close, permitting the range to be expanded again so we can avoid needing arbitrary precision variables.
For example (with 16-bit values for brevity) if range is 0x37ba to 0x37f0 then we can write out the top 8 bits (0x37) and shift low and high ranges left by 8 bits (0xba00 to 0xf040).
Care needs to be taken to cope with ranges that are numerically close but straddling a top byte value, such as 0x37fe to 0x3801.
In this case we reduce the high range to avoid running out of precision (high = 0x37ff) prior to flushing.

Pseudocode for the range codec decoding follows.  This implementation uses low and range instead of low and high, where $range = high - low$.
\texttt{low} is a 64-bit unsigned integer while \texttt{range} and \texttt{code} (the next few bytes of the compressed data stream) are 32-bit unsigned integers.

\textsc{RangeCreate} initialises the range coder, reading the first bytes of the compressed data stream.

\begin{algorithmic}[1]
\Procedure{RangeCreate}{}
  \settowidth{\maxwidth}{range\ }
  \State \algalign{low}{\gets} $0$\Comment{64-bit unsigned}
  \State \algalign{range}{\gets} $2^{32}-1$\Comment{Maximum 32-bit unsigned value}
  \State \algalign{code}{\gets} $0$\Comment{32-bit unsigned}
  \For{$i \gets 0$ to $7$}
    \State $code \gets (code << 8) + $\Call{ReadByte}{}
  \EndFor
\EndProcedure
\end{algorithmic}

Decoding each symbol is in two parts; getting the current frequency and updating the range.

\begin{algorithmic}[1]
\Function{RangeGetFreq}{$tot\_freq$}
  \State $range \gets range / tot\_freq$
  \State \Return $code / range$
\EndFunction
\end{algorithmic}

\begin{algorithmic}[1]
\Procedure{RangeDecode}{$sym\_low, sym\_freq, tot\_freq$}
  \settowidth{\maxwidth}{range\ }
  \State \algalign{temp}{\gets} $sym\_low \times range$\Comment{Temp is an unsigned 32-bit integer}
  \State \algalign{low}{\gets} $low + temp$
  \State \algalign{code}{\gets} $code - temp$
  \State \algalign{range}{\gets} $range \times sym\_freq$
  \While{$range < 2^{24}$} \Comment{Renormalise}
    \If{$((low>>56) \ne ((low+range)>>56)$}\Comment{Close but straddles top byte}
      \State $range = (low \bitor (2^{24}-1)) - low$
    \EndIf
    \State \algalign{code}{\gets} $(code<<8) + $\Call{ReadByte}{}
    \State \algalign{range}{\gets} $(range<<8)$
    \State \algalign{low}{\gets} $(low<<8)$
  \EndWhile
\EndProcedure
\end{algorithmic}

\subsubsection*{Statistical Modelling}

The probabilities passed to the range coder may be fixed for all scenarios (as we had in the ``cat'' example), or they may be adaptive and context aware.
For example the letter `u' occurs around 3\% of time in English text, but if the previous letter was `q' it is close to 100\% and if the previous letter was `u' it is close to 0\%.
Using the previous letter is known as an Order-1 entropy encoder, but the context can be anything.
We can also adaptively adjust our probabilities as we encode or
decode, learning the likelihoods and thus avoiding needing to store
frequency tables in the data stream covering all possible contexts.

To do this we use a statistical model, containing an array of symbols $S$ and their frequencies $F$.
The sum of these frequences must be less than $2^{16}-32$.
When they get too high, they are renormalised by approximately halving the frequencies (ensuring none drop to zero).

Typically an array of models are used where the array index represents the current context.

To encode any symbol the entropy encoder needs to know the frequency of the symbol to encode, the cumulative frequencies of all symbols prior to this symbol, and the total of all frequencies.
For decoding a cumulative frequency is obtained given the frequency total and the appropriate symbol is found matching this frequency.
Symbol frequencies are updated after each encode or decode call and the symbols are kept in order of most-frequent symbol first in order to  reduce the overhead of scanning through the cumulative frequencies.

\textsc{ModelCreate} initialises a model by setting every symbol to have a frequency of 1.
(At no point do we permit any symbol to have zero frequency.)

\begin{algorithmic}[1]
\Procedure{ModelCreate}{$num\_sym$}
  \State $total\_freq \gets num\_sym$
  \State $max\_sym \gets num\_sym-1$
  \For{$i \gets 0$ to $max\_sym$}
    \State $S_i \gets i$
    \State $F_i \gets 1$
  \EndFor
\EndProcedure
\end{algorithmic}

\textsc{ModelDecode} is called once for each decoded symbol.
It returns the next symbol and updates the model frequencies automatically.

\begin{algorithmic}[1]
\Function{ModelDecode}{rc}
  \State $freq \gets$ $rc.$\Call{RangeGetFrequency}{$total\_freq$}
  \State $x \gets 0$
  \State $acc \gets 0$
  \While{$acc + F_x <= freq$}
    \State $acc \gets acc + F_x$
    \State $x \gets x+1$
  \EndWhile
  \State $rc.$\Call{RangeDecode}{$acc,\ F_x,\ total\_freq$}
  \State $F_x \gets F_x + 8$ \Comment{Update model frequencies}
  \State $total\_freq \gets total\_freq + 8$
  \If{$total\_freq > 2^{16}-32$}
    \State \Call{ModelRenormalise}{}
  \EndIf
  \State $sym \gets S_x$
  \If{$x > 0$ and $F_x > F_{x-1}$}
    \State $tmp \gets F_x$ \Comment{swap $F_x$ with $F_{x-1}$}
    \State $F_x \gets F_{x-1}$
    \State $F_{x-1} \gets tmp$
    \State $tmp \gets S_x$ \Comment{swap $S_x$ with $S_{x-1}$}
    \State $S_x \gets S_{x-1}$
    \State $S_{x-1} \gets tmp$
  \EndIf
  \State \Return $sym$
\EndFunction
\end{algorithmic}

\textsc{ModelRenormalise} is called whenever the total frequencies get too high.
The frequencies are halved, taking sure to avoid any zeros.

\begin{algorithmic}[1]
\Procedure{ModelRenormalise}{}
  \State $total\_freq \gets 0$
  \For{$i \gets 0$ to $max\_sym$}
    \State $F_i \gets F_i - (F_i \bdiv 2)$
    \State $total\_freq \gets total\_freq + F_i$
  \EndFor
\EndProcedure
\end{algorithmic}

\subsubsection*{FQZComp Models}

The FQZComp process utilises knowledge of the read lengths, complement
(qualities reversed) status and a generic parameter selector, but in
order to maintain a strict separation between CRAM data series these
fields are stored (duplicated) within the quality data stream
itself. The strand and duplication models have no context and are have
boolean values.  The parameter selector model also has no context
associated with it and encodes $max\_sel$ distrinct values.  The
quality model has a 16-bit context used to address an array of
$2^{16}$ models, each model permitting $max\_sym$ distinct quality
values.  The context used is defined by the FQZcomp parameters, of
which there may be multiple sets, selected using the selector model.
There are 4 read length models each having $max\_sym$ of 256.  Each
model is used for the 4 successive bytes in a 32-bit length value.

The entropy encoder used is shared between all models, so the bit
stream is multiplexed together.

The quality values are modelled using a combined 16-bit context.  This
context is constructed by adding sub-contexts together consisting of
previous quality values, position along the current record, a running
count (per record) of how many times the quality value has differed to
the previous one (delta), and an arbitrary stored selector value, each
shifted to a defined location within the combined context value
($qloc$, $ploc$, $dloc$ and $sloc$ respectively).  The qual, pos
and delta sub-contexts are computed from the previous data while the
selector, if used, is read directly from the compressed data stream.
The selector may be used to switch parameter sets, or simply to group
quality strings into arbitrary user-defined sub-sets.  The numeric
values for each of these components can be passed through a lookup
table ($qtab$ for quality, $ptab$ for positions, $dtab$ for
running delta and $stab$ for turning the selector into a parameter
index $s$).  These convert the monotonically increasing range
0$\rightarrow$M to a monotonically increasing 0$\rightarrow$N.  For
example if we wish to use the approximate position, we may uniformly
map 0$\rightarrow$99 to 0$\rightarrow$7 to utilise 3 bits of our
16-bit combined context.

As some sequencing instruments produce binned qualities, eg 0, 10, 25,
35, these values are squashed to incremental values from 0 to
$max\_sym-1$ where $max\_sym$ is the maximum number of distinct
quality values observed.  If this transform is required, the flag
$have\_qmap$ will be set and a mapping table ($qmap$) will hold the
original quality values.  These should be referenced once each value
has been decoded.

The quality sub-context is constructed by shifting left the previous
quality sub-context by $qshift$ bits and adding the current quality
after passing through the $qmap$ squashing process and if defined
through the $qtab$ lookup table.  The quality context is limited to
$qbits$ long and is added to the combined context starting at bit
$qloc$.  The quality sub-context is reset to zero at the start of each
new record.
\footnote{For example if we have 4 quality values in use -- 0, 10, 25 and
35 -- we will be encoding quality values 0, 1, 2 and 3.  We may wish to
define $qbits$ to be 6 and $qshift$ to be 2 such that the previous 3
quality values can be used as context, for the prediction of the next
quality value.  There will likely be little reason to use $qtab$ in
this scenario, but an encoder could define $qtab$ to convert \{0, 1, 2, 3\}
to \{0, 0, 0, 1\} and use $qshift$ of 1 instead, giving us
knowledge of which of the previous 6 values were maximum quality.}

The position context is simply the number of remaining quality values
in this record, so is a value starting at record length and
decrementing).  As with the quality context it may be passed through a
lookup table $ptab$ before shifting left by $ploc$ bits and adding to
the combined context.

Delta is a count of the number of times the quality value has changed
from one value to a different one.  Thus a run of identical values
will not increase delta.  It gets reset to zero at the start of every
record.  It may be adjusted by the $dtab$ lookup table and is shifted
by $dloc$ before adding to the combined context.

The start of an FQZComp data stream consists of the parameters used by
the decoder. The data layout is as follows.

\begin{table}
\centering
\begin{tabular}{|r|r|r|r|r|p{8cm}|l|l|} 
\hline
\multicolumn{3}{|r|}{\textbf{Bits} }                   & \textbf{Type}  & \textbf{Name}                  & \multicolumn{3}{p{8.8cm}|}{\textbf{Description}} \\ 
\hline
\multicolumn{3}{|r|}{8}                                & uint8          & $version$                      & \multicolumn{3}{p{8.8cm}|}{FQZComp format version: must be 5}\\
\hline
\multicolumn{3}{|r|}{8}                                & uint8          & $gflags$                       & \multicolumn{3}{p{8.8cm}|}{Global FQZcomp bit-flags. From lowest bit to highest:}\\
\multicolumn{3}{|r|}{}                                 &                &                                & \multicolumn{3}{p{8.8cm}|}{1: $multi\_param$: indicates more than one parameter block is present.  Otherwise set $nparam = 1$} \\
\multicolumn{3}{|r|}{}                                 &                &                                & \multicolumn{3}{p{8.8cm}|}{2: $have\_stab$: indicates the parameter selector is mapped through $stab$.  Otherwise set $stab_i = i$} \\ 
\hline

\multicolumn{8}{|l|}{}\\[-0.7em]
\multicolumn{8}{|l|}{\textit{If $multi\_param$ gflag is set:} } \\ 
\cline{2-7}
                       & \multicolumn{2}{r|}{8}        & uint8          & \multicolumn{1}{l|}{$nparam$ } & \multicolumn{2}{p{8.4cm}|}{Number of parameter blocks (defaults to 1)} & \\
\cline{2-7}

\multicolumn{8}{|l|}{}\\[-0.5em]
\multicolumn{8}{|l|}{\textit{If $have\_tab$ gflag is set:} }                                                                                                                                 \\ 
\cline{2-7}
                       & \multicolumn{2}{r|}{8}        & uint8          & $max\_sel$                     & \multicolumn{2}{p{8.4cm}|}{Maximum parameter selector value} & \\
                       & \multicolumn{2}{r|}{variable} & table          & $stab$                         & \multicolumn{2}{p{8.4cm}|}{Parameter selector table} & \\
\cline{2-7}
\multicolumn{8}{|l|}{}\\
\hline
\hline
\multicolumn{8}{|l|}{}\\[-0.7em]
\multicolumn{8}{|l|}{\textit{Parameter block: repeated $nparam$ times: (selected via $model\_sel$ and $stab$)}} \\ 
\cline{2-7}
                       & \multicolumn{2}{r|}{16}        & uint16        & $context$                      & \multicolumn{2}{p{8.4cm}|}{Starting context value} & \\
\cline{2-7}
                       & \multicolumn{2}{r|}{8}        & uint8          & $pflags$                       & \multicolumn{2}{p{8.4cm}|}{Per-parameter block bit-flags. From lowest bit to highest:} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{1: $have\_qmap$: indicates quality map is present} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{2: $do\_deup$: model\_dup will be used} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{4: $do\_len$: model\_len will be used for every record.} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{16: $do\_rev$: $model\_revcomp$ will be used. (CRAM v3.1)} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{32: $have\_ptab$: Load $ptab$, otherwise position contexts are unused} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{64: $have\_dtab$: Load $dtab$, otherwise delta contexts are unused} & \\
                       & \multicolumn{2}{r|}{}         &                &                                & \multicolumn{2}{p{8.4cm}|}{128: $have\_qtab$: Load $qtab$, otherwise set $qtab_i = i$} &\\
\cline{2-7}
                       & \multicolumn{2}{r|}{8}        & uint8          & $max\_sym$                     & \multicolumn{2}{p{8.4cm}|}{Total number of distinct quality values} & \\ 
\cline{2-7}
                       & \multicolumn{2}{r|}{4}        & uint4 (high)   & qbits                          & \multicolumn{2}{p{8.4cm}|}{Total number of bits for quality context} & \\
                       & \multicolumn{2}{r|}{4}        & uint4 (low)    & qshift                         & \multicolumn{2}{p{8.4cm}|}{Left bit shift per successive quality in quality context} & \\
                       & \multicolumn{2}{r|}{4}        & uint4 (high)   & qloc                           & \multicolumn{2}{p{8.4cm}|}{Bit position of quality context} & \\
                       & \multicolumn{2}{r|}{4}        & uint4 (low)    & unused                         & \multicolumn{2}{p{8.4cm}|}{Zero} & \\
                       & \multicolumn{2}{r|}{4}        & uint4 (high)   & ploc                           & \multicolumn{2}{p{8.4cm}|}{Bit position of position context} & \\
                       & \multicolumn{2}{r|}{4}        & uint4 (low)    & dloc                           & \multicolumn{2}{p{8.4cm}|}{Bit position of delta context }& \\ 
\cline{2-7}

& \multicolumn{6}{l|}{} & \\[-0.7em]
\multicolumn{1}{|l|}{} & \multicolumn{6}{l|}{ \textit{If $have\_map$ pflag is set:} } & \\ 
\cline{3-6}
                       &  & variable                   & uint8[$max\_sym$]          & $qmap$             & Map for unbinning quality values. & & \\
\cline{3-6}

& \multicolumn{6}{l|}{} & \\[-0.5em]
\multicolumn{1}{|l|}{} & \multicolumn{6}{l|}{ \textit{If $have\_qtab$ pflag is set:} } & \\ 
\cline{3-6}
                       &  & variable                   & table          & $qtab$                         & Quality context lookup table & & \\
\cline{3-6}

& \multicolumn{6}{l|}{} & \\[-0.5em]
\multicolumn{1}{|l|}{} & \multicolumn{6}{l|}{ \textit{If $have\_tab$ pflag is set:} } & \\
\cline{3-6}
                       &  & variable                   & table          & $ptab$                         & Position context lookup table & & \\
\cline{3-6}

& \multicolumn{6}{l|}{} & \\[-0.5em]
\multicolumn{1}{|l|}{} & \multicolumn{6}{l|}{ \textit{If $have\_tab$ pflag is set:} } & \\
\cline{3-6}
                       &  & variable                   & table          & $dtab$                         & Delta context lookup table & & \\
\cline{3-6}
& \multicolumn{6}{l|}{} & \\
\cline{2-7}
\multicolumn{8}{|l|}{}\\
\hline
\end{tabular}
\end{table}

As an example configuration, with 8 distinct quality values we would
use $qmap$ to encode/decode qualities in the range 0-7 and can do
Order-3 entropy encoding by setting $qbits=9$ and $qshift=3$.  This
leaves 7 bits remaining, which would could distribute as 3 bits of
position (perhaps pos/16 or pos/32 to get approximate location), 3
bits of running delta/4, and a bit to distinguish READ1 from READ2.
Disagramatically the combined context layout would look this this:

\includegraphics[width=250pt, keepaspectratio=true]{img/fqz_bits.png}

In parameter terms we would use these values in the parameter block:

\begin{tabular}{lrl}
\hline
\textbf{Field} & \textbf{Value} & \textbf{Note}\\
\hline
qbits  & 9  & 3 bit each $\implies$ Order-3 Markov model \\
qshift & 3  & E.g. HiSeq X 8-binned, as 3 bit qmap \\
qloc   & 0  & No $qtab$ needed, but $qmap$ converts qual to 0-7 range.\\
\hline
ploc   & 9  & With $ptab$ performing pos/32 function.\\
\hline
dloc   & 12 & With $dtab$ performing delta/4 function.\\
\hline
sloc   & 15 & 1 bit, iff $do\_strand$ flag is set\\
\hline
\end{tabular}

FIXME: our worked example should include actual bytes for qmap, ptab
and dtab too.


\textsc{DecodeFQZParams} below describes the pseudocode for reading
the parameter block.

\begin{algorithmic}[1]
\Procedure{DecodeFQZParams}{}
  \State $vers \gets $\Call{ReadByte}{}
  \If{$vers \ne 5$}
    \State ERROR
  \EndIf
  \settowidth{\maxwidth}{have\_qtab\ }
  \State \algalign{flags}{\gets} \Call{ReadByte}{}
  \State \algalign{have\_qtab}{\gets}    $flags\bitand 128$
  \State \algalign{have\_dtab}{\gets}    $flags\bitand 64$
  \State \algalign{have\_ptab}{\gets}    $flags\bitand 16$
  \State \algalign{do\_rev}{\gets}    $flags\bitand 16$
  \State \algalign{do\_strand}{\gets} $flags\bitand 8$
  \State \algalign{do\_len}{\gets}    $flags\bitand 4$
  \State \algalign{do\_dedup}{\gets}  $flags\bitand 2$
  \State \algalign{have\_qmap}{\gets}   $flags\bitand 1$
  \State \algalign{max\_sym}{\gets} \Call{ReadByte}{}
  \If{$have\_qmap$}
    \State $max\_sym \gets$ \Call{ReadByte}{}
    \For{$i \gets 0$ to $max\_sym-1$}
      \State $qmap_i \gets$ \Call{ReadByte}{}
    \EndFor
  \EndIf
  \settowidth{\maxwidth}{qshift\ }
  \State \algalign{x}{\gets} \Call{ReadByte}{}
  \State \algalign{qshift}{\gets} $x \bmod 16$
  \State \algalign{qbits}{\gets} $x \bdiv 16$
  \State \algalign{x}{\gets} \Call{ReadByte}{}
  \State \algalign{sloc}{\gets} $x \bmod 16$
  \State \algalign{qloc}{\gets} $x \bdiv 16$
  \State \algalign{x}{\gets} \Call{ReadByte}{}
  \State \algalign{dloc}{\gets} $x \bmod 16$
  \State \algalign{ploc}{\gets} $x \bdiv 16$
  \If{$have\_qtab$}
    \State $qtab \gets$ \Call{ReadArray}{$256$}
  \Else
    \For{$i \gets 0$ to $256$}
      \State $qtab_i \gets i$
    \EndFor
  \EndIf
  \If{$have\_ptab$}
    \State $ptab \gets$ \Call{ReadArray}{$1024$}
  \EndIf
  \If{$have\_dtab$}
    \State $qtab \gets$ \Call{ReadArray}{$256$}
  \EndIf
\EndProcedure
\end{algorithmic}

\textsc{FQZCreateModels} creates the decoder models based on the above
parameters and the shared range coder.

\begin{algorithmic}[1]
\Procedure{FQZCreateModels}{}
  \State $rc \gets $\Call{RangeCreate}{}
  \For{$i \gets 0$ to $3$}
    \State $model\_len_i \gets $\Call{ModelCreate}{$256$}
  \EndFor
  \For{$i \gets 0$ to $2^{16}-1$}
    \State $model\_qual_i \gets $\Call{ModelCreate}{$max\_sym$}
  \EndFor
  \If{$do\_strand$}
    \State $model\_dup \gets $\Call{ModelCreate}{$2$}
  \EndIf
  \If{$do\_rev$}
    \State $model\_rev \gets $\Call{ModelCreate}{$2$}
  \EndIf
  \If{$do\_strand$}
    \State $model\_strand \gets $\Call{ModelCreate}{$2$}
  \EndIf
\EndProcedure
\end{algorithmic}

\textsc{ReadArray} reads an array $A$ of size $n$ which maps values 0
to $n-1$ to a smaller range (0 to $m-1$), both monotonically
increasing.  For efficiency this is done using a two-level run length
encoding.

Assuming $m < n$ there will be runs of the same value.  We measure run
lengths for all values (even if they are zero).  For example an array
$A = \{0,1,3,4,5,6,7,7,7,7\}$ may be converted to run lengths $R =
\{1,1,0,1,1,1,1,4\}$.  This array $R$ is no longer monotonically
increasing but still has repeated values, so is run-length encoded by
storing the number of additional values whenever the last two lengths
match.  This converts $R$ to $R2 = \{1, 1, +0, 0, 1, 1, +2, 4\}$ where
the `+' symbol is shown purely to indicate the values representing the
additional run-length copy numbers.

Finally, for coping with runs of 255 or more any run value of 255 is
assumed to be part of a larger run and the next value is read and
added to run-length until it is no longer 255.  For example run length
600 would be represented as 255 255 90.

The final array $R2$ is the stored data stream.  The decoder process
is the reverse of the above, starting by creating $R$ and then $A$,
for example using the following pseudocode.

\begin{algorithmic}[1]
\Function{ReadArray}{n}
\State $i,j,z \gets 0$
\State $last \gets -1$
\While{$z < n$} \Comment{Convert $R2$ to $R$}
  \State $run \gets $ \Call{ReadByte}{}
  \State $R_j \gets run$
  \State $j \gets j+1$
  \State $z \gets z + run$
  \If{$run = last$}
    \State $copy \gets $ \Call{ReadByte}{}
    \For{$x \gets 1 $ to $copy$}
      \State $R_j \gets run$
      \State $j \gets j+1$
    \EndFor
    \State $z \gets z + run \times copy$
  \EndIf
\EndWhile
\Statex
\State $i,j,z \gets 0$
\While{$z < n$} \Comment{Convert $R$ to $A$}
  \State $run\_len \gets 0$
  \Repeat
    \State $part \gets R_j$
    \State $j \gets j + 1$
    \State $run\_len \gets run\_len + part$
  \Until{$part \ne 255$}
  \For{$x \gets 1 $ to $run\_len$}
    \State $A_z \gets i$
    \State $z \gets z+1$
  \EndFor
  \State $i \gets i+1$
\EndWhile
\Statex
\State \Return $A$
\EndFunction
\end{algorithmic}

The main loop decodes data in the following order per read:  read
length (if not fixed), the flag for whether this is read 2 (if
needed), a bit flag to indicate if the quality is duplicated (if
needed), followed by record length number of quality values using
various data gathered since the start of this read as context.

The output of this function is an array of quality values in the
variable $output$, indexed with the $i^{th}$ value via $output_i$.
The output buffer is a concatenation of all quality values for each
record.  The record lengths are recorded, but note this is the number
of qualities encoded in CRAM for this sequence record and this does
not necessarily have to match the number of base calls (for example
where qualities are explicitly specified for SNP bases but not
elsewhere).

\algnewcommand{\algorithmicgoto}{\textbf{go to}}%
\algnewcommand{\Goto}[1]{\algorithmicgoto\ \texttt{#1}}%
\algnewcommand{\Label}{\State\unskip}

\begin{algorithmic}[1]
  \Procedure{DecodeFQZ}{}
  \If{$do\_len$}
    \State $fixed\_len \gets $\Call{DecodeLength}{rc}
  \EndIf
  \Statex
  \State $i \gets 0$\Comment{Position in total quality block}
  \State $pos \gets 0$\Comment{Position in current sequence}
  \Label \texttt{next\_record:}
  \While{$i < buf\_len$}
    \If{$pos = 0$}\Comment{Reset at start of each new record}
    \If{$do\_len$}
      \State $rec\_len \gets $\Call{DecodeLength}{rc}
    \Else
      \State $rec\_len \gets fixed\_len$
    \EndIf
    \State $pos \gets rec\_len$
    \Statex
    \If{$do\_rev$}
      \State $rev_{rec} \gets model\_rev.$\Call{ModelDecode}{$rc$}
      \State $len_{rec} \gets rec\_len$
    \EndIf
    \If{$do\_strand$}
      \State $is\_read2 \gets model\_strand.$\Call{ModelDecode}{$rc$}
    \EndIf
    \Statex
    \If{$do\_dedup$}
      \State $is\_dup \gets model\_dup.$\Call{ModelDecode}{$rc$}
      \If{$is\_dedup$}
        \For{$j \gets 0$ to $rec\_len-1$}
          \State $output_{i+j} \gets output_{i+j-rec\_len}$
        \EndFor
        \State $i \gets i+rec\_len$
        \State $rec \gets rec+1$
        \State \Goto{next\_record}
%        \State continue\Comment{back to While loop}
      \EndIf
    \EndIf
    \Statex
    \State $ctx, qctx, qlast, delta \gets 0$
  \EndIf
  \Statex
  \State $q \gets model\_qual_{ctx}.$\Call{ModelDecode}{$rc$}
  \Comment{Decode a single quality value}
  \State $qual \gets qmap_q$
  \State $output_i \gets qual$
  \Statex
  \State $qctx \gets (qctx << qshift) + qtab_q$\Comment{Update context}
  \State $ctx \gets (qctx\bitand (2^{qbits}-1)) << qloc$
  \If{$have\_ptab$}
    \State $ctx \gets ctx + ($\Call{Min}{$1024,\ ptab_{pos}$}$ << ploc)$
  \EndIf
  \If{$do\_strand$}
    \State $ctx \gets ctx + (is\_read2 << sloc)$
  \EndIf
  \If{$have\_dtab$}
    \State $ctx \gets ctx + ($\Call{Min}{$255,\ dtab_{delta}$}$ << dloc)$
  \EndIf
  \State $ctx \gets ctx\bitand (2^{16}-1)$
  \Statex
  \If{$qlast \ne qual$}
    \State $delta \gets delta + 1$
  \EndIf
  \State $qlast \gets qual$
  \State $i \gets i + 1$
  \State $pos \gets pos - 1$
\EndWhile
\If{$do\_rev$}
  \State \Call{ReverseQualities}{$output\ ,rev,\ len$}
\EndIf
\EndProcedure
\end{algorithmic}

Where \textsc{Min}($a,b$) returns the smallest integer value from $a$ and $b$.

\begin{algorithmic}[1]
  \Function{Min}{a,b}
  \If{$a < b$}
    \State \Return $a$
  \Else
    \State \Return $a$
  \EndIf
  \EndFunction
\end{algorithmic}

Read lengths are encoded as 4 8-bit bytes, each having its own model.

\begin{algorithmic}[1]
\Function{DecodeLength}{rc}
\State $rec\_len \gets model\_len_0.$\Call{ModelDecode}{$rc$}
\State $rec\_len \gets rec\_len + (model\_len_1.$\Call{ModelDecode}{$rc$}$ << 8)$
\State $rec\_len \gets rec\_len + (model\_len_2.$\Call{ModelDecode}{$rc$}$ << 16)$
\State $rec\_len \gets rec\_len + (model\_len_3.$\Call{ModelDecode}{$rc$}$ << 24)$
\State \Return $last\_len$
\EndFunction
\end{algorithmic}

For CRAMv4 quality values are stored in their original FASTQ
orientation.  For CRAMv3 they are stored in their alignment
orientation and it may be beneficial for compression purposes to
reverse them first.  If so $do\_rev$ will be set and the
\textsc{ReverseQualities} procedure called below after decoding.

\begin{algorithmic}[1]
\Procedure{ReverseQualities}{$qual,\ qual\_len,\ rev,\ len$}
\State $rec \gets 0$
\For{$i \gets 0$ to $qual\_len-1$}
  \If{$rev_{rec} \ne 0$}
    \State $k \gets len_{rec}-1$
    \For{$j \gets 0$ to $len_{rec}/2$}
      \State $tmp \gets qual_{i+j}$
      \State $qual_{i+j} \gets qual_{i+k}$
      \State $qual_{i+k} \gets tmp$
    \EndFor
  \EndIf
\EndFor
\EndProcedure
\end{algorithmic}


\subsection*{Name tokenisation codec}

Sequence names (identifiers) typically follow a structured pattern and
compression based on columns within those structures usually leads to
smaller sizes.

As an example, take a series of names:

\begin{verbatim}
I17_08765:2:123:61541:01763#9
I17_08765:2:123:1636:08611#9
I17_08765:2:124:45613:16161#9
\end{verbatim}

We may wish to tokenise each of these into 7 tokens, e.g.
``I17\_08765:2:'', ``123'', ``:'', ``61541'', ``:'', ``01763''and
``\#9''. Some of these are multi-byte strings, some single characters,
and some numeric, possibily with a leading zero.  We also observe some
regularly have values that match the previous line (the initial prefix
string, colons, ``\#9'') while others are numerically very close to the
value in the previous line (124 vs 123).

The name tokeniser compares each name against a previous name (which
is not necessarily the one immediately prior) and encodes this name
either as a series of differences to the previous name or marking it
as an exact duplicate.  A maximum of 128 tokens is permitted within
any single read name.

The tokens and values are stored in an array $T_{pos,type}$ of byte
streams, where pos 0 is reserved for name meta-data (whether a
duplicate name) and pos 1 onwards is for the first, second and later
tokens.  $Type$ is one of the token types listed below, corresponding
to the type of data being stored.  Some token types may also have
associated values.  Type TYPE (0) holds the token type itself and that
type is then used to retrieve the associated value(s) if appropriate.
Thus multiple types at the same token position will have their values
encoded in distinct data streams, e.g. is position 5 is of type either
DIGITS or DDELTA then data streams will exist for $T_{5,TYPE}$,
$T_{5,DIGITS}$ and $T_{5, DDELTA}$.  Decoding per name continues until
a token of type END is observed.

A simplistic pseudocode for decoding the $n^{th}$ individual name is:

\begin{algorithmic}[1]
  \Function{DecodeName}{$n$}
  \State $type \gets$ \Call{get\_type}{0,\ \texttt{TYPE}}
  \State $dist \gets$ \Call{get\_int32}{0,\ \texttt{TYPE}}
  \If{$type = $ \texttt{DUP}}
    \State $name_n \gets name_{n-dist}$
    \State \Return $name_n$
  \EndIf
  \Statex
  \State $pos \gets 0$
  \Repeat
    \State $pos \gets pos+1$
    \State $type \gets$ \Call{get\_type}{$pos$,\ \texttt{TYPE}}
    \State (Append to $name_n$ based on $type$)
  \Until{$type = $ \texttt{END}}
  \State \Return $name_n$
  \EndFunction
\end{algorithmic}


Token IDs (types) are listed below.

\begin{tabular}{lllp{10cm}}
\hline
\textbf{ID} & \textbf{Type} & \textbf{Value} & \textbf{Description}\\
\hline
 0 & TYPE    & Type    & Used to determine the type of token at a given position. \\
\hline
 5 & DUP     & Integer (distance) & The entire name is a duplicate of an earlier one.  Used in position 0 only.\\
 6 & DIFF    & Integer (distance) & The entire name is differs to earlier ones.  Used in position 0 only.\\
\hline
 1 & STRING  & String  & A string of characters \\
 2 & CHAR    & Byte    & A single character \\
 7 & DIGITS  & $0 \le$ Int $< 2^{32}$ & A numerical value, not containing a leadng zero \\
 4 & DIGITS0 & $0 \le$ Int $< 2^{32}$ & A numerical value possibly starting in leading zeros \\
 ? & DZLEN   & Int length & Length of DIGITS0 token.\\
11 & DDELTA  & $0 \le$ Int $< 256$   & A numeric value being stored as the difference to the value of this token on the previous name \\
12 & DDELTA0 & $0 \le$ Int $< 256$ & As DDELTA, but for numeric values starting with leading zeros \\
13 & MATCH   & (none) & This token is identical type and value to the same position in the previous name \\
14 & END     & (none) & Marks end of name\\
\hline
\end{tabular}

More detail on the token types is given below.

\begin{itemize}
\item{\textbf{TYPE}:}
This is the first token fetched at each token position.  It holds the
type of the token at this position, which in turn may then required
retrieval from type-specific data streams at this position.

For position 0, the TYPE field indicates whether this record is an
exact duplicate of a prior read name or has been encoded as a delta to
an earlier one.
  
\item{\textbf{DUP}, \textbf{DIFF}:}
These types are fetched for position 0, at the start of each new
identifier.  The value is an integer value describing how many reads
before this (with 1 being the immediately previous name) we are
comparing against.  When we refer to ``previous name'' below, we
always mean the one indicated by the DIFF field and not the one
immediately prior to the current name.

By convention the first record will have a DIFF of zero and no delta
or match operations are permitted.

\item{\textbf{STRING}:}
We fetch one byte at a time from the value array, appending to the
name buffer until the byte retrieved is zero.  The zero byte is not
stored in the name buffer.
For purposes of token type MATCH, a match is defined as entirely
matching the string including the length.

\item{\textbf{CHAR}:}
Fetch one single byte from the value array and append to the name buffer.

\item{\textbf{DIGITS}:}
Fetch 4 bytes from the value array and intrepret these as a little
endian unsigned integer.  This is appended to the name buffer as
string of base-10 digits, most significant digit first.  Larger
values may be represented, but will require multiple DIGITS tokens.
Negative values may be encoded by treating the minus sign as a CHAR or
STRING and storing the absolute value.

\item{\textbf{DIGITS0}, \textbf{DZLEN}:}
This fetches the 4 bytes value from $T_{pos,DIGITS0}$ and a 1 byte
length from $T_{pos,DZLEN}$.  As per DIGITS, the value is intrepreted as a
little endian unsigned integer.  The length indicates the total
size of the numeric value when displayed in base 10 which must be
greater than $\log_{10}(value)$ with any remaining length indicating
the number of leading zeros.  For example if DIGITS0 value is 123 and
DZLEN length is 5 the string ``00123'' must be appended to the name.

For purposes of the MATCH type, both primary and secondary lengths
must match.

\item{\textbf{DDELTA}:}
Fetch a 1 byte value and add this to the DIGITS value from the
previous name.  It is invalid to have a DDELTA token when the previous
name does not have a DIGITS token at this position.

For the purposes of a MATCH type, the DDELTA value is assumed to match
meaning we have another increment by the same amount.

\item{\textbf{DDELTA0}:}
As per DDELTA, but the 1 byte value retrieved is added to the DIGITS0
value in the previous name.  No DZLEN value is retrieved, with the
length from the previous name being used instead.

For the purposes of a MATCH type, the DDELTA0 value is assumed to match
meaning we have another increment by the same amount and display to
the same length.

\item{\textbf{MATCH}:}
This token matches the token at the same position in the previous
name.  (The previous name is permitted to also have a MATCH token at
this position, in which case it recurses to its previous name.)

The definition of MATCH is token type specific, as described above.
No value is needed for MATCH tokens.

\item{\textbf{END}:}
Marks the end of the name.  A nul byte is added to the name output
buffer.  No value is needed for END tokens.
\end{itemize}

Given a complex name and both position and type specific values, this
can lead to many separate data streams.  These are serialised into
a single byte stream.

The packed data stream starts with two unsigned little endiand 32-bit
integers holding the total size of uncompressed name buffer and the
number of read names.  This is followed the array elements
themselves.

Token types, $ttype$ holds one of the token ID values listed above
in the list above, plus special values to indicate certain additional
flags.  Bit 6 (64) set indicates that this entire token data stream is a
duplicate of one earlier.  Bit 7 (128) set indicates the token
is the first token at a new position.

The total size of the serialised stream needs to be already known, in
order to determine when the token types finish.

\begin{tabular}{|r|r|r|l|l|p{10cm}|}
\hline
\multicolumn{3}{|r|}{\textbf{Bytes}} & \textbf{Type} & \textbf{Name} & \textbf{Description}\\
\hline
\multicolumn{3}{|r|}{4} & uint32 & $uncomp\_length$ & Length of uncompressed name buffer\\
\multicolumn{3}{|r|}{4} & uint32 & $num\_reads$ & Number of read names\\
\hline
\multicolumn{6}{|l|}{\quad\textit{For each token data stream}}\\
\cline{2-6}
& \multicolumn{2}{r|}{1} & uint8 & $ttype$ & Token type code.\\
\cline{2-6}
& \multicolumn{5}{l|}{\textit{If ttype AND 64 (duplicate)}}\\
\cline{3-6}
& & 1 & uint8 & $dup\_pos$  & Duplicate from this token position\\
& & 1 & uint8 & $dup\_type$ & Duplicate from this token type ID\\
\cline{3-6}
& \multicolumn{5}{l|}{\textit{else if not duplicate}}\\
\cline{3-6}
& & ? & i7 & $clen$ & compressed length (7-bit encoding)\\
& & $clen$ & $cdata$ & stream & compressed data stream\\
\hline
\end{tabular}

TODO: write simple pseudocode for this stage.

The $cdata$ stream itself can be compressed using a variety of
methods.  The first byte is a format flag with a series of method bits:

\begin{tabular}{llll}
\hline
\textbf{Bit number} & \textbf{Bit AND value} & \textbf{Code} & \textbf{Description} \\
\hline
0 & 1 & ORDER & Order-0 or Order-1 entropy coding. \\
1 & 2 & reserved & Reserved (for possible order-2/3)\\
2 & 4 & DICT & map 32-bit values to 8-bit\\
3 & 8 & X4 & 4-way interleaving of byte streams.\\
4 & 16 & NOSIZE & original size is not recorded (used by X4)\\
5 & 32 & CAT & Data is uncompressed\\
6 & 64 & RLE & Run length encoding, with runs and literals encoded separately\\
7 & 128 & PACK & Pack 2, 4, 8 or infinite symbols per byte.\\
\hline
\end{tabular}

The data layout differs for each of these bit types, as described
below.  Some of these can be used in combination, so the order needs
to be observed.  The order of evaluation is (TODO).  For example value
193 is PACK, then RLE, then Order-1 entropy encoding.

\begin{algorithmic}[1]
\Function{ArithDecode}{$len$}
  \State $flags \gets $\Call{ReadByte}{}
  \If{$flags \bitand 8$} \Comment{X4}
    \State $out \gets $\Call{DecodeX4}{$len$}
    \Return $out$
  \EndIf{}
  \Statex
  \If{$flags \bitand 16 \ne 0$} \Comment{not NO\_SIZE}
    \State $out\_len \gets$\Call{ReadInt7}{}
  \EndIf
  \If{$flags \bitand 4$} \Comment{DICT}
    \State $D \gets $\Call{DecodeDictMeta}{}
  \EndIf
  \If{$flags \bitand 128$} \Comment{PACK}
    \State $P \gets $\Call{DecodePackMeta}{}
  \EndIf
  \If{$flags \bitand 32$} \Comment{CAT}
    \State $data \gets $\Call{DecodeCat}{}
  \EndIf
  \If{$flags \bitand 64$} \Comment{RLE}
    \If{$flags \bitand 1$} \Comment{ORDER}
      \State $data \gets $\Call{DecodeRLE1}{}
    \Else
      \State $data \gets $\Call{DecodeRLE0}{}
    \EndIf
  \EndIf
  \If{$flags \bitand 128$} \Comment{PACK}
    \State $data \gets $\Call{DecodePack}{$data$}
  \EndIf
  \State $out \gets data$ 
  \EndFunction
\end{algorithmic}

\begin{itemize}
\item{\textbf{ORDER}:}
Defines order-0 or order-1 entropy encoding, as used by the arithmetic
coder described in the Statistical Modelling section.

\begin{algorithmic}[1]
\Function{DecodeOrder0}{$len$}
  \State $max\_sym \gets $\Call{ReadByte}{}
  \State $model\_lit \gets $\Call{ModelCreate}{$max\_sym$}
  \Statex
  \For{$i \gets 0$ to $len-1$}
    \State $out_i \gets model\_lit.$\Call{ModelDecode}{$rc$}
  \EndFor
  \State \Return $out$
\EndFunction
\end{algorithmic}

\begin{algorithmic}[1]
\Function{DecodeOrder1}{$len$}
  \State $max\_sym \gets $\Call{ReadByte}{}
  \For{$i \gets 0$ to $max\_sym-1$}
    \State $model\_lit_i \gets $\Call{ModelCreate}{$max\_sym$}
  \EndFor
  \Statex
  \State $last \gets 0$
  \For{$i \gets 0$ to $len-1$}
    \State $out_i \gets model\_lit_{last}.$\Call{ModelDecode}{$rc$}
    \State $last \gets out_i$
  \EndFor
  \State \Return $out$
\EndFunction
\end{algorithmic}

\item{\textbf{DICT}:}
FIXME: we have expanded size 4 mandated, but only store them as 16-bit
values with a 16-to-32 expansion explicitly coded into the algorithm.
We should generalise this, as well as doing it correctly! Maybe
high-4-bit is stride size and low-4-bit is stored size, to permit
future improvements?

FIXME: maybe the whole thing is just an LZ predefined dictionary as a
first pass before encoding names?  This permits up to 128 dictionary
lookups and intermingling of normal bytes with longer dictionary tokens?

This maps fixed size multi-byte values $V_n$ to single-byte values
$\{0, 1, ... n-1\}$.  The first byte indicates the multi-byte stride
size to map.  Currently this must be 4.  The next byte holds the
number of values in the map ($n$). Following this is a run-length
encoding of the map.  The byte-stream consists of a byte holding the
number of literals in a row in the top 4 bits and the number of runs
of consecutive literals in a row in the bottom 4 bits.  For each
literal, the next 16-bits (little endian) represent the value.
Despite this only being 16 bit in size, it is expanded to a 32-bit
number (with 16-bit of leading zeros) in the uncompressed byte stream.
For each run the value is numerically one higher than before and is
not stored.  For example $V_n =
\{1000,1100,1200,1201,1202,1203,1204,2200\}$ could be stored as
$\{(3<<4)+4, \textit{1000}, \textit{1100}, \textit{1200}, (1<<4)+0, \textit{2200}\}$ with the actual
values shown in italics taking up 16-bits each.

The compressed data stream follows, encoded according to the other
format bit flags. Once the bytes have been uncompressed a new data
stream is generated by replacing each byte value $x$ with the unsigned
32-bit value $V_x$, thus growing the byte stream by 4 times.
  
\begin{algorithmic}[1]
\Function{DecodeDictMeta}{$len$}
  \State $stride \gets $\Call{ReadByte}{}
  \State $n \gets $\Call{ReadByte}{}
  \State $i \gets 0$
  \While{$i < n$}
    \State $x \gets $\Call{ReadByte}{}
    \State $lit \gets x \bmod 16$
    \State $run \gets x \bdiv 16$
    \For{$j \gets 0$ to $lit-1$}
      \State $D_{i+j} \gets $\Call{ReadInt16}{}
    \EndFor
    \State $i \gets i + lit$
    \If{$run > 0$}
      \For{$j \gets 0$ to $run-1$}
        \State $D_{i+j} \gets D_{i+j-1}+1$
      \EndFor
      \State $i \gets i + run$
    \EndIf
  \EndWhile
  \State \Return $D,\ stride$
\EndFunction
\end{algorithmic}

\begin{algorithmic}[1]
\Function{DecodeDict}{$data,\ out\_len$}
  \State $i \gets 0$
  \For{$j \gets 0$ to $out\_len-1$}
  \State $v \gets data_j$
  \State $out_{i+0} \gets (D_v >> \ 0) \bitand 255$
  \State $out_{i+1} \gets (D_v >> \ 8) \bitand 255$
  \State $out_{i+2} \gets (D_v >> 16) \bitand 255$ 
  \State $out_{i+3} \gets (D_v >> 24) \bitand 255$
  \State $i \gets i + 4$ \Comment{Only implemented for $stride = 4$}
 \EndFor
  \State \Return $out$
\EndFunction
\end{algorithmic}

\item{\textbf{X4}:}
The byte stream consists of a 7-bit encoded uncompressed length, which
must be a multiple of 4, followed by 4 compressed lengths also 7-bit
encoded.  Each of these compressed byte streams is then itself a valid
$cdata$ stream and will recurse again, each starting with their own
format flag.  The total uncompressed byte stream is then an
interleaving of one byte in turn from each of the 4 substreams (in
order of 1st to 4th).  Thus an array of 32-bit unsigned integers could
be unpacked using X4 to compress each of the 8-bit components together
with their own algorithm.

\begin{algorithmic}[1]
\Function{DecodeX4}{$len$}
  \State $ulen \gets $\Call{ReadInt7}{}
  \State $plen \gets ulen / 4$
  \For{$i \gets 0$ to $3$} \Comment{Fetch 4 compressed lengths}
    \State $clen_i \gets $\Call{ReadInt7}{}
  \EndFor
  \State $X0 \gets $\Call{ArithDecode}{$plen$} \Comment{Decode 4 streams}
  \State $X1 \gets $\Call{ArithDecode}{$plen$}
  \State $X2 \gets $\Call{ArithDecode}{$plen$}
  \State $X3 \gets $\Call{ArithDecode}{$plen$}
  \Statex
  \State $i \gets 0$
  \For{$j \gets 0$ to $plen-1$} \Comment{Interleave}
    \State $out_{i+0} \gets X0_j$
    \State $out_{i+1} \gets X1_j$
    \State $out_{i+2} \gets X2_j$
    \State $out_{i+3} \gets X3_j$
    \State $i \gets i+4$
  \EndFor
  \State \Return $out$
\EndFunction
\end{algorithmic}

\item{\textbf{NOSIZE}:}
Do not store the size of the uncompressed data stream.  This
information is not required when the data stream is one of the
sub-four streams in the X4 format.

\item{\textbf{CAT}:}
The uncompressed data stream is the same as the compressed stream.
This is useful for very short data where the overheads of compressing
are too high.

\begin{algorithmic}[1]
\Function{DecodeCat}{$len$}
  \For{$i \gets 0$ to $len-1$}
    \State $out_i \gets $\Call{ReadByte}{}
  \EndFor
  \State \Return $out$
\EndFunction
\end{algorithmic}

% \item{\textbf{RLE}:}
% For run-length encoded data streams the stream consists of a list of
% run-lengths (optionally order-0 entropy encoded) followed by list of
% run-lengths followed by a list of literals (non-run byte values),
% entropy encoded using whatever scheme the format flags indicate.
% 
% The data stream starts with 7-bit encoded uncompressed meta-data size
% followed by 7-bit encoded uncompressed literal-data size.  The bottom
% bit of the meta-data size is a flag to indicate whether the
% run-lengths as stored uncompressed (1) or order-0 entropy encoded (0).
% In both cases the actual size of the run-lengths is halved, by
% shifting out the bottom bit flag.  If the run lengths are entropy
% encoded, its byte stream starts with a 7-bit encoded size of the
% compressed run-length stream (otherwise this is the same as the
% uncompressed meta-data size).
% 
% The run length mechanism used always stores run lengths for certain
% byte values and never for other values, irrespective of the run
% lengths.  The run-length byte stream starts with an 8-bit value
% holding the number of literals for which runs will be stored, with
% value 0 meaning all 256 possible literals.  This is then followed by
% the literal values for which runs are stored.  Run lengths are stored
% using the big-endian 7-bit notation, but as $length-1$ given a run
% length of zero can never be stored (the literal would not be
% present).
% 
% For example if `R' and `U` are deemed to be worthy of
% storing run lengths while `N' is not, then for the string
% ``URRRRUNNURUUN'' the byte stream starts with
% \{2, `R',`U'\}, the run lengths (minus one) for `U' and `R's only
% \{0,3,0,0,0,1\}, and literals \{U,R,U,N,N,U,R,U,N\}.
% 
% FIXME: reimplement this using adaptive arith with run map being
% computed on-the-fly (run using literal as context, or delta and run0
% only).

\item{\textbf{RLE}:}
For run-length encoded data streams an additional model is used to
hold the number of occurences of each symbol, with the symbols them
being order-0 or order-1 depending on the ORDER flag.

After the symbol is decoded, the run length must be decoded to
indicate how many \emph{extra} copies of this symbol occur.  Long runs
are broken into a series of lengths of no more than 15.  If length 15
is decoded it indicates we must decode an additional length and add to
the current one.  The context used for the run length model is the
symbol itself for the initial run, 256 for the first continuation run
(if $\ge 16$) and 257 for any further continuation runs.  Thus encoding
50 `A' characters would first store symbol `A' followed by run length
15 (with context `A'), length 15 (context 256), length 15 (context
257), and length 5 (context 258).

For example, if we have the string ``RRRRUNN'' we will decode
symbol `R' run 3, symbol `U' run 0, symbol `N' run 1.

\begin{algorithmic}[1]
\Function{UnRLE0}{$len$}
  \State $max\_sym \gets $\Call{ReadByte}{}
  \State $model\_lit \gets $\Call{ModelCreate}{$max\_sym$}
  \For{$i \gets 0$ to $257$}
    \State $model\_run_i \gets $\Call{ModelCreate}{$16$}
  \EndFor
  \Statex
  \State $i \gets 0$
  \While{$i < len$}
    \State $out_i \gets model\_lit.$\Call{ModelDecode}{$rc$}
    \State $part \gets model\_run_{out_i}.$\Call{ModelDecode}{$rc$}
    \State $run \gets part$
    \State $rctx \gets 256$
    \While{$part = 15$}
      \State $part \gets model\_run_{rctx}.$\Call{ModelDecode}{$rc$}
      \State $rctx \gets 257$
      \State $run \gets run + part$
    \EndWhile
    \For{$j \gets 1$ to $run$}
      \State $out_{i+j} \gets out_i$
    \EndFor
    \State $i \gets run+1$
  \EndWhile
  \State \Return $out$
\EndFunction
\end{algorithmic}

The order-1 run length variant is identical to order-0 except the
previous symbol is used as the context for the next literal.  The
context for the run length does not change.

\begin{algorithmic}[1]
\Function{UnRLE1}{$len$}
  \State $max\_sym \gets $\Call{ReadByte}{}
  \For{$i \gets 0$ to $max\_sym-1$}
    \State $model\_lit_i \gets $\Call{ModelCreate}{$max\_sym$}
  \EndFor
  \For{$i \gets 0$ to $257$}
    \State $model\_run_i \gets $\Call{ModelCreate}{$16$}
  \EndFor
  \Statex
  \State $last \gets 0$
  \State $i \gets 0$
  \While{$i < len$}
    \State $out_i \gets model\_lit_{last}.$\Call{ModelDecode}{$rc$}
    \State $last \gets out_i$
    \State $part \gets model\_run_{last}.$\Call{ModelDecode}{$rc$}
    \State $run \gets part$
    \State $rctx \gets 256$
    \While{$part = 15$}
      \State $part \gets model\_run_{rctx}.$\Call{ModelDecode}{$rc$}
      \State $rctx \gets 257$
      \State $run \gets run + part$
    \EndWhile
    \For{$j \gets 1$ to $run$}
      \State $out_{i+j} \gets last$
    \EndFor
    \State $i \gets run+1$
  \EndWhile
  \State \Return $out$
\EndFunction
\end{algorithmic}

\item{\textbf{PACK}:}
Data containing only 1, 2, 4 or 16 distinct values can have multiple
values packed into a single byte (infinite, 8, 4 or 2).  The distinct
symbol values do not need to be adjacent as a mapping table $M$
converts quantised value $x$ to original symbol $M_x$ where $x$ is the
number of distinct possible symbols.

The first byte holds $nsym$, the number of distinct values, followed
by $nsym$ bytes to construct the $M$ map.  If $nsym = 1$ then the byte
stream is a stream of constant values and no bit-packing is done (we
know every value already).  If $nsym = 2$ then each symbol is 1 bit (8
per byte), if $2 < nsym \le 4$ symbols are 2 bits each (4 per byte)
and if $4 < nsym \le 16$ symbols are 4 bits each (2 per byte). It is
not permitted to have $nsym > 16$ as bit packing is not possible.
Bits are unpacked from low to high.

\begin{algorithmic}[1]
\Function{Unpack}{$len$}
  \State $n \gets $\Call{ReadByte}{} \Comment{Read map $M_0$ to $M_{n-1}$}
  \For{$i \gets 0$ to $n-1$}
    \State $M_i \gets $ \Call{ReadByte}{}
    \EndFor
  \Statex
  \If{$n <= 1$} \Comment{Constant value}
    \For{$i \gets 0$ to $len-1$}
      \State $out_i \gets M_0$
    \EndFor
  \Statex
  \ElsIf{$n <= 2$} \Comment{1 bit per value}
    \For{$i \gets 0$ to $len-1$}
      \If{$i \bmod 8 = 0$}
        \State $v \gets$ \Call{ReadByte}{}
      \EndIf
      \State $out_i \gets M_{(v \bitand 1)}$
      \State $v = v >> 1$
    \EndFor
  \Statex
  \ElsIf{$n <= 4$} \Comment{2 bits per value}
    \For{$i \gets 0$ to $len-1$}
      \If{$i \bmod 4 = 0$}
        \State $v \gets$ \Call{ReadByte}{}
      \EndIf
      \State $out_i \gets M_{(v \bitand 3)}$
      \State $v = v >> 2$
    \EndFor
  \Statex
  \ElsIf{$n <= 16$} \Comment{4 bits per value}
    \For{$i \gets 0$ to $len-1$}
      \If{$i \bmod 2 = 0$}
        \State $v \gets$ \Call{ReadByte}{}
      \EndIf
      \State $out_i \gets M_{(v \bitand 15)}$
      \State $v = v >> 4$
    \EndFor
  \Statex
  \Else
    \State \Call{Error}{}
  \EndIf
  \Statex
  \State \Return out
\EndFunction
\end{algorithmic}

\end{itemize}

\end{document}
